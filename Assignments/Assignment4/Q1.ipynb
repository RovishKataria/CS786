{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1. (30 points)\n",
    "Implement a GCM encoding these assumptions and give me quantitative predictions on the test set.\n",
    "Submit both code and category responses for the data points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.read_csv(\"X.csv\", names=[\"weight\", \"height\", \"label\"])\n",
    "y_df = pd.read_csv(\"y.csv\", names=[\"weight\", 'height'])\n",
    "\n",
    "X_features = X_df.iloc[:, :2].values # numpy array\n",
    "X_labels = X_df.iloc[:, 2].values\n",
    "y_features = y_df.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GCM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(test_point, train_features, train_labels, alpha_weight=2, alpha_height=1, beta=1):\n",
    "    # Define attention weights for each training point\n",
    "    alpha = np.array([alpha_weight, alpha_height])\n",
    "    \n",
    "    # Calculating similarity for each training point\n",
    "    similarities = []\n",
    "    for i, exemplar in enumerate(train_features):\n",
    "        # Computing distance\n",
    "        distance = np.sum(alpha * np.abs(exemplar - test_point))\n",
    "        \n",
    "        # Computing similarity\n",
    "        similarity = np.exp(-beta * distance)\n",
    "        \n",
    "        # Appending similarity along with its label\n",
    "        similarities.append((similarity, train_labels[i]))\n",
    "\n",
    "    # Aggregating similarities by category\n",
    "    small_sim = sum(similar for similar, label in similarities if label == 1)\n",
    "    average_sim = sum(similar for similar, label in similarities if label == 2)\n",
    "    large_sim = sum(similar for similar, label in similarities if label == 3)\n",
    "\n",
    "    # Apply politeness bias: reduce the similarity weight for \"large\"\n",
    "    large_sim *= 0.8  # This factor represents the politeness adjustment\n",
    "\n",
    "    # Choose category with highest similarity score\n",
    "    similarities_dict = {1: small_sim, 2: average_sim, 3: large_sim}\n",
    "    return max(similarities_dict, key=similarities_dict.get)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2, 3, 2, 2, 3, 2, 2, 2, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [calculate_similarity(test_point, X_features, X_labels) for test_point in y_features]\n",
    "predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df.to_csv('Q1_Category_Label.csv', index=False, header=False)\n",
    "print(\"Predictions are saved to Q1_Category_Label.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
