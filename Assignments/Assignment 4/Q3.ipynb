{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3. (30 points)\n",
    "For both GCM and RMC, show empirically using the dataset I've shared that both models assume exchangeability of data,\n",
    "viz. the order in which data enters the model does not affect the category labels of the model for any given subset of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = pd.read_csv(\"X.csv\", names=[\"weight\", \"height\", \"label\"])\n",
    "y_df = pd.read_csv(\"y.csv\", names=[\"weight\", 'height'])\n",
    "\n",
    "X_features = X_df.iloc[:, :2].values \n",
    "X_labels = X_df.iloc[:, 2].values\n",
    "y_features = y_df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity(test_point, train_features, train_labels, alpha_weight=2, alpha_height=1, beta=1):\n",
    "    # Define attention weights for each training point\n",
    "    alpha = np.array([alpha_weight, alpha_height])\n",
    "\n",
    "    # Calculating similarity for each training point\n",
    "    similarities = []\n",
    "    for i, exemplar in enumerate(train_features):\n",
    "        # Computing distance\n",
    "        distance = np.sum(alpha * np.abs(exemplar - test_point))\n",
    "        \n",
    "        # Computing similarity\n",
    "        similarity = np.exp(-beta * distance)\n",
    "        \n",
    "        # Appending similarity along with its label\n",
    "        similarities.append((similarity, train_labels[i]))\n",
    "\n",
    "    # Aggregating similarities by category\n",
    "    small_sim = sum(similar for similar, label in similarities if label == 1)\n",
    "    average_sim = sum(similar for similar, label in similarities if label == 2)\n",
    "    large_sim = sum(similar for similar, label in similarities if label == 3)\n",
    "\n",
    "    # Apply politeness bias: reduce the similarity weight for \"large\" and increase for \"average\"\n",
    "    large_sim *= 0.8  \n",
    "    average_sim *= 1.2  # Increase similarity weight for \"average\"\n",
    "\n",
    "    # Choose category with highest similarity score\n",
    "    similarities_dict = {1: small_sim, 2: average_sim, 3: large_sim}\n",
    "    return max(similarities_dict, key=similarities_dict.get)\n",
    "\n",
    "def likelihood(weight, height, category, params):\n",
    "    # Calculating likelihood for weight and height\n",
    "    weight_likelihood = norm.pdf(weight, params[category]['weight_mean'], params[category]['weight_std'])\n",
    "    height_likelihood = norm.pdf(height, params[category]['height_mean'], params[category]['height_std'])\n",
    "    \n",
    "    # Adjusting likelihood based on weight's higher importance\n",
    "    likelihood = (weight_likelihood ** 0.7) * (height_likelihood ** 0.3)\n",
    "    return likelihood\n",
    "\n",
    "def posterior_prob(weight, height, params):\n",
    "    # Calculating posterior probability for each category\n",
    "    posterior_probs = {}\n",
    "    categories = ['small', 'average', 'large']\n",
    "    cat_labels = {category: i + 1 for i, category in enumerate(categories)}\n",
    "    \n",
    "    for category in categories:\n",
    "        cat_label = cat_labels[category]\n",
    "        posterior_probs[cat_label] = likelihood(weight, height, category, params)\n",
    "    \n",
    "    # Normalizing the probabilities so that they sum to 1\n",
    "    total_posterior = sum(posterior_probs.values())\n",
    "    for cat_label in posterior_probs:\n",
    "        posterior_probs[cat_label] /= total_posterior\n",
    "    \n",
    "    return posterior_probs\n",
    "\n",
    "def predict_cat_label(posterior_probs):\n",
    "    # Returning the category with the highest posterior probability\n",
    "    return max(posterior_probs, key=posterior_probs.get)\n",
    "\n",
    "def predict_test_instances(y_test, params):\n",
    "    # Predicting labels for y.csv\n",
    "    y_predictions = []\n",
    "    \n",
    "    for i, test_instance in enumerate(y_test):\n",
    "        weight, height = test_instance\n",
    "        posterior_probs = posterior_prob(weight, height, params)\n",
    "        \n",
    "        # Finding the category with the highest posterior probability\n",
    "        predicted_label = predict_cat_label(posterior_probs)\n",
    "        \n",
    "        y_predictions.append(predicted_label)\n",
    "        # print(f\"Test instance {i + 1}\\nWeight = {weight}, Height = {height}, Predicted label = {predicted_label}\\n\")\n",
    "    \n",
    "    return y_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gcm_exchangeability_test(X_features, X_labels, y_features):\n",
    "    # Original predictions\n",
    "    original_predictions = [calculate_similarity(test_point, X_features, X_labels) for test_point in y_features]\n",
    "    \n",
    "    # Shuffle training data\n",
    "    shuffled_X = np.concatenate((X_features, X_labels.reshape(-1, 1)), axis=1)\n",
    "    np.random.shuffle(shuffled_X)\n",
    "    shuffled_features = shuffled_X[:, :2]\n",
    "    shuffled_labels = shuffled_X[:, 2]\n",
    "    \n",
    "    # Predictions after shuffling\n",
    "    shuffled_predictions = [calculate_similarity(test_point, shuffled_features, shuffled_labels) for test_point in y_features]\n",
    "    \n",
    "    # Compare predictions\n",
    "    return np.array_equal(original_predictions, shuffled_predictions)\n",
    "\n",
    "def rmc_exchangeability_test(X, y_test, params):\n",
    "    # Original predictions\n",
    "    original_predictions = predict_test_instances(y_test, params)\n",
    "    \n",
    "    # Shuffle training data\n",
    "    np.random.shuffle(X)\n",
    "    \n",
    "    # Recalculate parameters\n",
    "    weights = X[:, 0]\n",
    "    heights = X[:, 1]\n",
    "    labels = X[:, 2]\n",
    "    params = {\n",
    "        'small': {\n",
    "            'weight_mean': np.mean(X[labels == 1, 0]),\n",
    "            'weight_std': np.std(X[labels == 1, 0]),\n",
    "            'height_mean': np.mean(X[labels == 1, 1]),\n",
    "            'height_std': np.std(X[labels == 1, 1])\n",
    "        },\n",
    "        'average': {\n",
    "            'weight_mean': np.mean(X[labels == 2, 0]),\n",
    "            'weight_std': np.std(X[labels == 2, 0]),\n",
    "            'height_mean': np.mean(X[labels == 2, 1]),\n",
    "            'height_std': np.std(X[labels == 2, 1])\n",
    "        },\n",
    "        'large': {\n",
    "            'weight_mean': np.mean(X[labels == 3, 0]),\n",
    "            'weight_std': np.std(X[labels == 3, 0]),\n",
    "            'height_mean': np.mean(X[labels == 3, 1]),\n",
    "            'height_std': np.std(X[labels == 3, 1])\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Predictions after shuffling\n",
    "    shuffled_predictions = predict_test_instances(y_test, params)\n",
    "    \n",
    "    # Compare predictions\n",
    "    return np.array_equal(original_predictions, shuffled_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCM exchangeability test: True\n",
      "RMC exchangeability test: True\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    X = pd.read_csv('X.csv', header=None).values\n",
    "    y_test = pd.read_csv('y.csv', header=None).values\n",
    "    \n",
    "    # GCM exchangeability test\n",
    "    gcm_result = gcm_exchangeability_test(X_features, X_labels, y_features)\n",
    "    print(f\"GCM exchangeability test: {gcm_result}\")\n",
    "    \n",
    "    # RMC exchangeability test\n",
    "    params = {\n",
    "        'small': {\n",
    "            'weight_mean': np.mean(X[X[:, 2] == 1, 0]),\n",
    "            'weight_std': np.std(X[X[:, 2] == 1, 0]),\n",
    "            'height_mean': np.mean(X[X[:, 2] == 1, 1]),\n",
    "            'height_std': np.std(X[X[:, 2] == 1, 1])\n",
    "        },\n",
    "        'average': {\n",
    "            'weight_mean': np.mean(X[X[:, 2] == 2, 0]),\n",
    "            'weight_std': np.std(X[X[:, 2] == 2, 0]),\n",
    "            'height_mean': np.mean(X[X[:, 2] == 2, 1]),\n",
    "            'height_std': np.std(X[X[:, 2] == 2, 1])\n",
    "        },\n",
    "        'large': {\n",
    "            'weight_mean': np.mean(X[X[:, 2] == 3, 0]),\n",
    "            'weight_std': np.std(X[X[:, 2] == 3, 0]),\n",
    "            'height_mean': np.mean(X[X[:, 2] == 3, 1]),\n",
    "            'height_std': np.std(X[X[:, 2] == 3, 1])\n",
    "        }\n",
    "    }\n",
    "    # RMC exchangeability test\n",
    "    rmc_result = rmc_exchangeability_test(X, y_test, params)\n",
    "    print(f\"RMC exchangeability test: {rmc_result}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Explanation\n",
    "##### GCM (Generalized Context Model) Exchangeability Test: True\n",
    "This indicates that the GCM's categorization predictions remain unchanged when the training data is shuffled. This suggests:\n",
    "1. The model's attention weights and similarity calculations are robust.\n",
    "2. The model's performance is consistent, regardless of the training data order.\n",
    "\n",
    "##### RMC (Rational Model of Categorization) Exchangeability Test: True\n",
    "This result implies that the RMC's categorization predictions remain consistent when the training data is shuffled.\n",
    "Model parameters (e.g., means and standard deviations) are recalculated.\n",
    "This suggests:\n",
    "1. The model's likelihood calculations and posterior probability estimates are stable.\n",
    "2. The model's performance is reliable and insensitive to training data order."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
